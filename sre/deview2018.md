# DEVIEW 2018: Search Reliability Engineering

https://tv.naver.com/v/4580088



## 1. 들어가며

- SRE의 업무는 소방관과 비슷하다. 하지만 더 중요한 것은 장애가 나지 않도록, 그리고 장애가 나더라도 대응이 쉽도록 평소에 잘 대비하는 것이다.

- 어떻게 하면 장애를 예방할 수 있을지, 어떻게 하면 비용 효율적으로 장애에 대응할 수 있을지를 고민함.
- 두가지 난제
  - 장애 예방 비용이 장애가 났을 때 발생하는 손해 비용보다 적다는 것을 증명해야함
  - 장애가 나지 않는다면 SRE 덕분인지, 그냥 안나는 건지 증명해야함

- 글로벌 기업에서의 SRE 패턴을 그대로 갖다 쓰기는 어려움. 자체적으로 고민하고 해결해나가고 있다.
- 네이버에서 SRE
  - 모든 검색서비스 정상 동작
  - 1년에 10분 이하 다운타임
  - 고비용 사후 처리보다 저비용 사전 예방
  - 위 목표 달성을 위한 모든 활동



## 2. 네이버 검색 시스템의 SRE

- SRE를 도입하기 전에도 SRE와 비슷한 업무는 있었다. 이전에는 성능 엔지니어링 이라고 불렀다.

- 그 때나 지금이나 모든 활동의 시작은 지표를 관찰하는 것이다.
- 서비스와 서버가 많아질수록 지표를 보기가 힘들어졌다. 효율적인 관리 필요.
  - 통일된 규칙으로 서비스 ID 발급
  - 구조 가시화 -> 트래픽 흐름을 한눈에 볼 수 있고 원인 추적에 도움됨
  - 성능 / 비용 측정
- 가용량 지표 개발
  - 어떤 서비스는 서버 한대 죽어도 괜찮은데 어떤 서비스는 문제 발생. 이런 지표를 어떻게 나타낼까?
  - 기존 가용량 지표는 `장애 시간 / 전체 시간`. 이 지표로 99.998%라면 굉장히 좋아 보이지만 이는 1년동안 10분 장애임. 네이버 검색 10분 장애는 대재난이므로 이 지표는 도움이 안됨.
  - 분산 시스템에 맞는 가용량 지표를 개발.
    - 부하증가배수: 한 노드가 죽었을 때 형제 노드들이 현재의 몇 배 부하를 받는가?
    - 최대가용배수: 한 노드가 현재의 몇 배까지의 부하를 받을 수 있는가?
    - 임계 상황: 부하증가배수 > 최대가용배수
- 부하증가배수와 최대가용배수를 이용하여 가용량 경보 시스템 구성
  - 임계 상황 발생 횟수가 90% 감소
  - 그 다음은? 임계 상황 발생 원인을 분석할 수 있게 여러 요인들의 대시보드 개발

- SRE 업무는 이런 선순환 사이클
  - 새로운 지표 개발 -> 관제 범위 확대 -> 시스템 개발 -> 새로운 방법론 개발 -> 새로운 지표 개발
- 사이클이 돌 때마다 장애는 줄어들고 모두가 행복해질 것만 같지만 현실은 그렇지 않다.
  - 감시 지표가 많아질 수록 경보의 수가 너무 많아짐. (경보 폭탄, 경보 피로) 이번엔 경보 수를 줄여보자.

- 경보는 4가지로 분류된다.

|             | 긴급 대응 필요                                        | 대응 불필요                                     |
| ----------- | ----------------------------------------------------- | ----------------------------------------------- |
| 경보 발생   | True Positive (실제 장애)                             | False Positive (시간이 흐르면 정상화 되는 상황) |
| 경보 미발생 | False Negative (장애가 발생했으나 경보가 울리지 않음) | True Negative                                   |

여기서 중요한 건 `False Positive`와 `False Negative` . `False Negative`는 있으면 안되는 경우임. `False Negative`를 줄이기 위해 `False Positive`를 늘리게 된다. 지난 3년간 한 번만 겪음.

- 경보 피로의 주범은 `False Positive`다. 이걸 어떻게 줄일까?
  - 그래프를 보고 경험적으로 판단. 개인마다 숙련도 차이가 발생.
  - 자동화하면 좋은데 모든 경우를 자동화하는 건 불가능함. 대신,
    - 빠른 대응을 위해 필요한 데이터를 미리 모아주고
    - 기본적인 상황 판단 자동화
- 자동 경보 분석 예
  - CPU 사용량이 높아져 경보 발생. 같은 시기에 캐시 히트율 감소. -> 캐시 리프레시로 인한 일시적 CPU 증가이며 장애 아님으로 판단. CPU 사용량 그래프와 캐시 히트율 그래프의 기울기를 분단위로 분석하여 기울기의 정도에 따라 1~7까지 번호를 매겨 같은 패턴인지 검사.
  - 복제 서버들 중에서 하나의 서버에만 장애가 났는지를 코사인 유사도로 자동 판단.

